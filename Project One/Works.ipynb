{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,zipfile,os,shutil,time,wget,re\n",
    "from pathlib import Path\n",
    "\n",
    "from multiprocessing import Process, Queue, Pool\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-24\n",
      "2020\n",
      "3\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "d = date.today()\n",
    "\n",
    "print(d)\n",
    "print(d.year)\n",
    "print(d.month)\n",
    "print(d.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-03-24'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = d.isoformat()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lahman():\n",
    "    print('\\n Downloading Lahman Zip \\n')                                          #print statement\n",
    "        \n",
    "    R =  Path('./Lahman')                                                          #make path\n",
    "    if R.exists() is False:                                                        #check if path does not exist\n",
    "        os.makedirs('Lahman')                                                      #Make path if not\n",
    "    os.chdir(\"./Lahman\")                                                           #go to the new path\n",
    "    try: \n",
    "        wget.download('http://seanlahman.com/files/database/baseballdatabank-master_2018-03-28.zip', 'lahman.zip')#download the zipfile\n",
    "        zipfile.ZipFile('lahman.zip').extractall('.')                              #Unzip file\n",
    "        os.remove('lahman.zip')                                                    #remove file from system \n",
    "    except:\n",
    "        pass\n",
    "    os.chdir('..')                                                                 #go back to past directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Downloading Lahman Zip \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lahman()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Retrosheets():\n",
    "    print(' \\n Downloading Player CSV \\n')                                                      #print statment\n",
    "        \n",
    "    p = 'https://www.retrosheet.org/retroID.htm'                                                #URL download\n",
    "    wget.download(p, 'player.csv')                                                              #download link\n",
    "\n",
    "    with open('player.csv', encoding='cp1252') as f:                                            #Open file\n",
    "        lines = f.readlines()                                                                   #read lines of file\n",
    "    r = \"(\\w+,\\w+,\\w+,\\w+/\\S+)\"                                                                 #regex lines\n",
    "    match = re.finditer(r,str(lines))                                                           #search to match in the file\n",
    "        \n",
    "    print(' \\n Parsing Player CSV \\n')\n",
    "        \n",
    "    with open(\"players.csv\", \"w\") as f1:                                                        #make new player file\n",
    "        f1.write('ID'+','+'Last'+','+'First'+','+'Play_debut'+','+'Mgr_debut'+','+'Coach_debut'+','+'Ump_debut'+\"\\n\")\n",
    "        for m in match:\n",
    "            f1.write(m.group(1) + '\\n')                                                         #write the group to file\n",
    "    os.remove('player.csv')                                                                     #remove file\n",
    "    \n",
    "    print('\\n Downloading Retrosheets zips \\n ')                                                \n",
    "    R =  Path('./Retrosheets/Roster')                                                           #make path\n",
    "    if R.exists() is False:                                                                     #check if exist\n",
    "        os.makedirs('Retrosheets/Roster')                                                       #Make path if needed\n",
    "    T =  Path('./Retrosheets/Team')\n",
    "    if T.exists() is False:\n",
    "        os.makedirs('Retrosheets/Team')\n",
    "    E =  Path('./Retrosheets/Events')\n",
    "    if E.exists() is False:\n",
    "        os.makedirs('Retrosheets/Events')\n",
    "    try:   \n",
    "        shutil.move('players.csv', './Retrosheets')                                             #move the player file to retrosheets folder\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for i in range(1900,2020):                                                                  #Range of year\n",
    "        try: \n",
    "            year = i                                                                            #set year to the loop\n",
    "            p = 'https://www.retrosheet.org/events/' + str(year) + 'eve.zip'                    #URL maker\n",
    "            wget.download(p)                                                                    #download Zip\n",
    "            print('\\n Downloading Regular Season: ' + str(year) )                               #print statment\n",
    "            zipfile.ZipFile(str(year) + 'eve.zip').extractall('.')                              #unzip\n",
    "            for file in os.listdir(\"./\"):                                                       #get the files in this section\n",
    "                try:\n",
    "                \n",
    "                    if file.endswith(\".ROS\"):\n",
    "                        shutil.move(file, R)\n",
    "                    elif file.endswith(str(year)):\n",
    "                        shutil.move(file, T)\n",
    "                    elif file.endswith(\".EVN\"):\n",
    "                        shutil.move(file, E)\n",
    "                    elif file.endswith(\".EVA\"):\n",
    "                        os.remove(file)\n",
    "                    elif file.endswith(\"EVN\"):\n",
    "                        os.remove(file)\n",
    "                    elif file.endswith(\"EDA\"):\n",
    "                        os.remove(file)\n",
    "                    elif file.endswith(\"EDN\"):\n",
    "                        os.remove(file)\n",
    "                    elif file.endswith(\"zip\"):\n",
    "                        os.remove(file)\n",
    "                except:\n",
    "                    os.remove(file)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for i in range(1900,2020):\n",
    "        try: \n",
    "            year = i\n",
    "            p = 'https://www.retrosheet.org/events/' + str(year) + 'post.zip'\n",
    "            wget.download(p)\n",
    "            print('\\n Downloading Playoffs: ' + str(year) )\n",
    "            zipfile.ZipFile(str(year) + 'post.zip').extractall('.')\n",
    "            for file in os.listdir(\"./\"):\n",
    "                try:\n",
    "\n",
    "                    if file.endswith(\".EVE\"):\n",
    "                        shutil.move(file, E)\n",
    "                    elif file.endswith(str(year)):\n",
    "                        os.remove(file)\n",
    "                    elif file.endswith(\"ROS\"):\n",
    "                        os.remove(file)\n",
    "                    elif file.endswith(\"zip\"):\n",
    "                        os.remove(file)\n",
    "                except:\n",
    "                    os.remove(file)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Downloading Player CSV \n",
      "\n",
      " \n",
      " Parsing Player CSV \n",
      "\n",
      "\n",
      " Downloading Retrosheets zips \n",
      " \n",
      "\n",
      " Downloading Regular Season: 1918\n",
      "\n",
      " Downloading Regular Season: 1919\n",
      "\n",
      " Downloading Regular Season: 1920\n",
      "\n",
      " Downloading Regular Season: 1921\n",
      "\n",
      " Downloading Regular Season: 1922\n",
      "\n",
      " Downloading Regular Season: 1923\n",
      "\n",
      " Downloading Regular Season: 1924\n",
      "\n",
      " Downloading Regular Season: 1925\n",
      "\n",
      " Downloading Regular Season: 1926\n",
      "\n",
      " Downloading Regular Season: 1927\n",
      "\n",
      " Downloading Regular Season: 1928\n",
      "\n",
      " Downloading Regular Season: 1929\n",
      "\n",
      " Downloading Regular Season: 1930\n",
      "\n",
      " Downloading Regular Season: 1931\n",
      "\n",
      " Downloading Regular Season: 1932\n",
      "\n",
      " Downloading Regular Season: 1933\n",
      "\n",
      " Downloading Regular Season: 1934\n",
      "\n",
      " Downloading Regular Season: 1935\n",
      "\n",
      " Downloading Regular Season: 1936\n",
      "\n",
      " Downloading Regular Season: 1937\n",
      "\n",
      " Downloading Regular Season: 1938\n",
      "\n",
      " Downloading Regular Season: 1939\n",
      "\n",
      " Downloading Regular Season: 1940\n",
      "\n",
      " Downloading Regular Season: 1941\n",
      "\n",
      " Downloading Regular Season: 1942\n",
      "\n",
      " Downloading Regular Season: 1943\n",
      "\n",
      " Downloading Regular Season: 1944\n",
      "\n",
      " Downloading Regular Season: 1945\n",
      "\n",
      " Downloading Regular Season: 1946\n",
      "\n",
      " Downloading Regular Season: 1947\n",
      "\n",
      " Downloading Regular Season: 1948\n",
      "\n",
      " Downloading Regular Season: 1949\n",
      "\n",
      " Downloading Regular Season: 1950\n",
      "\n",
      " Downloading Regular Season: 1951\n",
      "\n",
      " Downloading Regular Season: 1952\n",
      "\n",
      " Downloading Regular Season: 1953\n",
      "\n",
      " Downloading Regular Season: 1954\n",
      "\n",
      " Downloading Regular Season: 1955\n",
      "\n",
      " Downloading Regular Season: 1956\n",
      "\n",
      " Downloading Regular Season: 1957\n",
      "\n",
      " Downloading Regular Season: 1958\n",
      "\n",
      " Downloading Regular Season: 1959\n",
      "\n",
      " Downloading Regular Season: 1960\n",
      "\n",
      " Downloading Regular Season: 1961\n",
      "\n",
      " Downloading Regular Season: 1962\n",
      "\n",
      " Downloading Regular Season: 1963\n",
      "\n",
      " Downloading Regular Season: 1964\n",
      "\n",
      " Downloading Regular Season: 1965\n",
      "\n",
      " Downloading Regular Season: 1966\n",
      "\n",
      " Downloading Regular Season: 1967\n",
      "\n",
      " Downloading Regular Season: 1968\n",
      "\n",
      " Downloading Regular Season: 1969\n",
      "\n",
      " Downloading Regular Season: 1970\n",
      "\n",
      " Downloading Regular Season: 1971\n",
      "\n",
      " Downloading Regular Season: 1972\n",
      "\n",
      " Downloading Regular Season: 1973\n",
      "\n",
      " Downloading Regular Season: 1974\n",
      "\n",
      " Downloading Regular Season: 1975\n",
      "\n",
      " Downloading Regular Season: 1976\n",
      "\n",
      " Downloading Regular Season: 1977\n",
      "\n",
      " Downloading Regular Season: 1978\n",
      "\n",
      " Downloading Regular Season: 1979\n",
      "\n",
      " Downloading Regular Season: 1980\n",
      "\n",
      " Downloading Regular Season: 1981\n",
      "\n",
      " Downloading Regular Season: 1982\n",
      "\n",
      " Downloading Regular Season: 1983\n",
      "\n",
      " Downloading Regular Season: 1984\n",
      "\n",
      " Downloading Regular Season: 1985\n",
      "\n",
      " Downloading Regular Season: 1986\n",
      "\n",
      " Downloading Regular Season: 1987\n",
      "\n",
      " Downloading Regular Season: 1988\n",
      "\n",
      " Downloading Regular Season: 1989\n",
      "\n",
      " Downloading Regular Season: 1990\n",
      "\n",
      " Downloading Regular Season: 1991\n",
      "\n",
      " Downloading Regular Season: 1992\n",
      "\n",
      " Downloading Regular Season: 1993\n",
      "\n",
      " Downloading Regular Season: 1994\n",
      "\n",
      " Downloading Regular Season: 1995\n",
      "\n",
      " Downloading Regular Season: 1996\n",
      "\n",
      " Downloading Regular Season: 1997\n",
      "\n",
      " Downloading Regular Season: 1998\n",
      "\n",
      " Downloading Regular Season: 1999\n",
      "\n",
      " Downloading Regular Season: 2000\n",
      "\n",
      " Downloading Regular Season: 2001\n",
      "\n",
      " Downloading Regular Season: 2002\n",
      "\n",
      " Downloading Regular Season: 2003\n",
      "\n",
      " Downloading Regular Season: 2004\n",
      "\n",
      " Downloading Regular Season: 2005\n",
      "\n",
      " Downloading Regular Season: 2006\n",
      "\n",
      " Downloading Regular Season: 2007\n",
      "\n",
      " Downloading Regular Season: 2008\n",
      "\n",
      " Downloading Regular Season: 2009\n",
      "\n",
      " Downloading Regular Season: 2010\n",
      "\n",
      " Downloading Regular Season: 2011\n",
      "\n",
      " Downloading Regular Season: 2012\n",
      "\n",
      " Downloading Regular Season: 2013\n",
      "\n",
      " Downloading Regular Season: 2014\n",
      "\n",
      " Downloading Regular Season: 2015\n",
      "\n",
      " Downloading Regular Season: 2016\n",
      "\n",
      " Downloading Regular Season: 2017\n",
      "\n",
      " Downloading Regular Season: 2018\n",
      "\n",
      " Downloading Regular Season: 2019\n",
      "\n",
      " Downloading Playoffs: 1903\n",
      "\n",
      " Downloading Playoffs: 1905\n",
      "\n",
      " Downloading Playoffs: 1906\n",
      "\n",
      " Downloading Playoffs: 1907\n",
      "\n",
      " Downloading Playoffs: 1908\n",
      "\n",
      " Downloading Playoffs: 1909\n",
      "\n",
      " Downloading Playoffs: 1910\n",
      "\n",
      " Downloading Playoffs: 1911\n",
      "\n",
      " Downloading Playoffs: 1912\n",
      "\n",
      " Downloading Playoffs: 1913\n",
      "\n",
      " Downloading Playoffs: 1914\n",
      "\n",
      " Downloading Playoffs: 1915\n",
      "\n",
      " Downloading Playoffs: 1916\n",
      "\n",
      " Downloading Playoffs: 1917\n",
      "\n",
      " Downloading Playoffs: 1918\n",
      "\n",
      " Downloading Playoffs: 1919\n",
      "\n",
      " Downloading Playoffs: 1920\n",
      "\n",
      " Downloading Playoffs: 1921\n",
      "\n",
      " Downloading Playoffs: 1922\n",
      "\n",
      " Downloading Playoffs: 1923\n",
      "\n",
      " Downloading Playoffs: 1924\n",
      "\n",
      " Downloading Playoffs: 1925\n",
      "\n",
      " Downloading Playoffs: 1926\n",
      "\n",
      " Downloading Playoffs: 1927\n",
      "\n",
      " Downloading Playoffs: 1928\n",
      "\n",
      " Downloading Playoffs: 1929\n",
      "\n",
      " Downloading Playoffs: 1930\n",
      "\n",
      " Downloading Playoffs: 1931\n",
      "\n",
      " Downloading Playoffs: 1932\n",
      "\n",
      " Downloading Playoffs: 1933\n",
      "\n",
      " Downloading Playoffs: 1934\n",
      "\n",
      " Downloading Playoffs: 1935\n",
      "\n",
      " Downloading Playoffs: 1936\n",
      "\n",
      " Downloading Playoffs: 1937\n",
      "\n",
      " Downloading Playoffs: 1938\n",
      "\n",
      " Downloading Playoffs: 1939\n",
      "\n",
      " Downloading Playoffs: 1940\n",
      "\n",
      " Downloading Playoffs: 1941\n",
      "\n",
      " Downloading Playoffs: 1942\n",
      "\n",
      " Downloading Playoffs: 1943\n",
      "\n",
      " Downloading Playoffs: 1944\n",
      "\n",
      " Downloading Playoffs: 1945\n",
      "\n",
      " Downloading Playoffs: 1946\n",
      "\n",
      " Downloading Playoffs: 1947\n",
      "\n",
      " Downloading Playoffs: 1948\n",
      "\n",
      " Downloading Playoffs: 1949\n",
      "\n",
      " Downloading Playoffs: 1950\n",
      "\n",
      " Downloading Playoffs: 1951\n",
      "\n",
      " Downloading Playoffs: 1952\n",
      "\n",
      " Downloading Playoffs: 1953\n",
      "\n",
      " Downloading Playoffs: 1954\n",
      "\n",
      " Downloading Playoffs: 1955\n",
      "\n",
      " Downloading Playoffs: 1956\n",
      "\n",
      " Downloading Playoffs: 1957\n",
      "\n",
      " Downloading Playoffs: 1958\n",
      "\n",
      " Downloading Playoffs: 1959\n",
      "\n",
      " Downloading Playoffs: 1960\n",
      "\n",
      " Downloading Playoffs: 1961\n",
      "\n",
      " Downloading Playoffs: 1962\n",
      "\n",
      " Downloading Playoffs: 1963\n",
      "\n",
      " Downloading Playoffs: 1964\n",
      "\n",
      " Downloading Playoffs: 1965\n",
      "\n",
      " Downloading Playoffs: 1966\n",
      "\n",
      " Downloading Playoffs: 1967\n",
      "\n",
      " Downloading Playoffs: 1968\n",
      "\n",
      " Downloading Playoffs: 1969\n",
      "\n",
      " Downloading Playoffs: 1970\n",
      "\n",
      " Downloading Playoffs: 1971\n",
      "\n",
      " Downloading Playoffs: 1972\n",
      "\n",
      " Downloading Playoffs: 1973\n",
      "\n",
      " Downloading Playoffs: 1974\n",
      "\n",
      " Downloading Playoffs: 1975\n",
      "\n",
      " Downloading Playoffs: 1976\n",
      "\n",
      " Downloading Playoffs: 1977\n",
      "\n",
      " Downloading Playoffs: 1978\n",
      "\n",
      " Downloading Playoffs: 1979\n",
      "\n",
      " Downloading Playoffs: 1980\n",
      "\n",
      " Downloading Playoffs: 1981\n",
      "\n",
      " Downloading Playoffs: 1982\n",
      "\n",
      " Downloading Playoffs: 1983\n",
      "\n",
      " Downloading Playoffs: 1984\n",
      "\n",
      " Downloading Playoffs: 1985\n",
      "\n",
      " Downloading Playoffs: 1986\n",
      "\n",
      " Downloading Playoffs: 1987\n",
      "\n",
      " Downloading Playoffs: 1988\n",
      "\n",
      " Downloading Playoffs: 1989\n",
      "\n",
      " Downloading Playoffs: 1990\n",
      "\n",
      " Downloading Playoffs: 1991\n",
      "\n",
      " Downloading Playoffs: 1992\n",
      "\n",
      " Downloading Playoffs: 1993\n",
      "\n",
      " Downloading Playoffs: 1995\n",
      "\n",
      " Downloading Playoffs: 1996\n",
      "\n",
      " Downloading Playoffs: 1997\n",
      "\n",
      " Downloading Playoffs: 1998\n",
      "\n",
      " Downloading Playoffs: 1999\n",
      "\n",
      " Downloading Playoffs: 2000\n",
      "\n",
      " Downloading Playoffs: 2001\n",
      "\n",
      " Downloading Playoffs: 2002\n",
      "\n",
      " Downloading Playoffs: 2003\n",
      "\n",
      " Downloading Playoffs: 2004\n",
      "\n",
      " Downloading Playoffs: 2005\n",
      "\n",
      " Downloading Playoffs: 2006\n",
      "\n",
      " Downloading Playoffs: 2007\n",
      "\n",
      " Downloading Playoffs: 2008\n",
      "\n",
      " Downloading Playoffs: 2009\n",
      "\n",
      " Downloading Playoffs: 2010\n",
      "\n",
      " Downloading Playoffs: 2011\n",
      "\n",
      " Downloading Playoffs: 2012\n",
      "\n",
      " Downloading Playoffs: 2013\n",
      "\n",
      " Downloading Playoffs: 2014\n",
      "\n",
      " Downloading Playoffs: 2015\n",
      "\n",
      " Downloading Playoffs: 2016\n",
      "\n",
      " Downloading Playoffs: 2017\n",
      "\n",
      " Downloading Playoffs: 2018\n",
      "\n",
      " Downloading Playoffs: 2019\n"
     ]
    }
   ],
   "source": [
    "Retrosheets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your start year: 2019\n",
      "What is your start month: 1\n",
      "What is your start day: 1\n",
      "How many threads: 2\n",
      "Execution completed in 0.1351935863494873 seconds\n"
     ]
    }
   ],
   "source": [
    "MLB_Gamedata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the file...\n",
      "\n",
      "Extracting the file to Lahman...\n",
      "\n",
      "Removing unecessary zip file...\n",
      "\n",
      "\n",
      "The file was downloaded to: \n",
      "/home/brian/Data3402/Project1/Lahman\n",
      "Now the current working directory is: /home/brian/Data3402/Project1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/brian/Data3402/Project1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import sys,zipfile,os,shutil,time,wget,re\n",
    "    from pathlib import Path\n",
    "    from multiprocessing import Process, Queue, Pool\n",
    "    from datetime import date, timedelta\n",
    "    def retro():\n",
    "            inp1 = int(input('What is your start year: '))                                  #UserInput of information\n",
    "            inp2 = int(input('What is your start month: '))\n",
    "            inp3 = int(input('What is your start day: '))\n",
    "            inp4 = int(input('What is your end year: '))                                  #UserInput of information\n",
    "            inp5 = int(input('What is your end month: '))\n",
    "            inp6 = int(input('What is your end day: '))\n",
    "            inp7 = int(input('How many threads: '))       \n",
    "\n",
    "\n",
    "            def get_GIDs(q):\n",
    "                '''\n",
    "                Function to get GameIDs and Random Game Numbers\n",
    "                Input: Queue of dates of a range\n",
    "                Output: Queue and dictionary of the GameIDs and Random Numbers, List of all directories with Game Numbers, \n",
    "                Note: Make sure the function of this directory is located in the \n",
    "                '''\n",
    "\n",
    "                day = q.get()                                                                                              #Get the first item in the Queue    \n",
    "                All_urls = []                                                                                              #Start a list of all the Searchable URLs \n",
    "                while (day != 'Done'):\n",
    "                    All_urls.append('./MLB_Gameday_Data/year_' + str(day[0:4]) + '/month_'+ str(day[5:7]) + '/day_' + str(day[8:10])) #making the URLs with string slicing. Append it to the list                            \n",
    "                    day = q.get()                                                                                          #Get the next queue item for the while loop\n",
    "                ID_dic = {}                                                                                                #make a dictionary \n",
    "                GID_queue = Queue()                                                                                        #make a new queue for the GIDs to be placed in\n",
    "\n",
    "                r = '(\\w+)/\\S\\S(\\w+_[0-9]{4}_[0-9]{2}_[0-9]{2}_\\w+_\\w+_[0-9])'                                             #this is the Regex code for the GIDs. first group is for the random numbers , second group is for the GIDs\n",
    "                for i in range(0,len(All_urls)):                                                                           #for loop for the length of the URLs. We read the index file in each folder\n",
    "                    with open(All_urls[i] + '/index.html', 'r') as f:\n",
    "                        try:                                                                                               #we try to read if there is a file and match the regex \n",
    "                            lines = f.readlines()\n",
    "                            matches = re.finditer(r,str(lines))                                                            #for any matches we will match them in the groupings\n",
    "                            for m in matches:\n",
    "                                GID_queue.put(m.group(2))                                                                  #For each match, we will queue the GIDs\n",
    "                                ID_dic[m.group(1)] = m.group(2)                                                            #Create a dictionary with Random Numbers Keys and GIDs Values\n",
    "                        except:\n",
    "                            pass\n",
    "                GID_Search(ID_dic, GID_queue, All_urls)                                                                    #Call the new function because we are using local variables \n",
    "\n",
    "\n",
    "\n",
    "            def GID_Search(Dict, GID, url):\n",
    "                '''\n",
    "                Function to check GIDs and Random Numbers to match them. \n",
    "                Input: Dictionary of game values and GIDs, a queue of GIDs , a list of URls that are searchable\n",
    "                Output: create new directories of the GIDs and move them to the new Directory called MLB_GIDs in the Main project folder\n",
    "\n",
    "                '''\n",
    "                home_dir = os.getcwd()                                                                                     #takes the home Directory that is set for the project to be created in\n",
    "                MLB_GIDs =  Path('./MLB_GIDs')                                                                             #Checks if MLB_GIDs Directory is existing, if not, create the path\n",
    "                if MLB_GIDs.exists() is False:\n",
    "                    os.makedirs('./MLB_GIDs')\n",
    "                Move_file = home_dir + '/MLB_GIDs'\n",
    "                GID.put('Done')                                                                                            #adds done to the then of the queue to know when to stop\n",
    "                GameID = GID.get()\n",
    "                urlNumber = 0\n",
    "                while (GameID != 'Done' and urlNumber < len(url)):                                                         #when both the queue is not done and the URLs are not all gone though do this function below\n",
    "\n",
    "                    os.chdir(home_dir)                                                                                     #go to the home dir\n",
    "                    os.chdir(url[urlNumber])                                                                               #go to the Directory that is to be searched\n",
    "                    list_dir = os.listdir()                                                                                #get a list of items in the directory \n",
    "                    GameID = GID.get()\n",
    "                    urlNumber += 1                                                                                         #update the URL\n",
    "                    try:                                                                                                   #try if there are items in the directory listed\n",
    "                        for i in list_dir:                                                                                 #for each item in the directory, add it to the list but only if it is not the index.html file in each directory\n",
    "                            Game_numbers = []\n",
    "                            if i != 'index.html':\n",
    "                                Game_numbers.append(i)\n",
    "\n",
    "                            for i in Game_numbers:                                                                         #for each item in that list without the index.html file\n",
    "                                File_name = Dict.get(i)                                                                    #search that item in the directory keys to get a value and set that to the variable File_name\n",
    "                                \n",
    "                                try:                                                                                       #try function here is to try to create and move files, if the game already exist then you do not have to do anything but if not create and move\n",
    "                                    GID_path =  Path('./MLB_GIDs/' + str(File_name))                                       #Make a path URL\n",
    "                                    if GID_path.exists() is False:                                                         #check if it exist and if not make it \n",
    "                                        os.makedirs(Move_file+ '/' + str(File_name))\n",
    "                                    os.chdir('./' + i )                                                                    #go into the Random numbers folder that contains 2 xml files\n",
    "                                    xml_files = os.listdir()                                                               #get a list of that directory items\n",
    "                                    for i in xml_files:                                                                    #for each item in that directory, move it to the new directory that was created\n",
    "                                        shutil.copyfile(i, Move_file + '/' + str(File_name) + '/' + str(i))                #used the copy file function to move\n",
    "                                        \n",
    "                                    os.chdir('..')                                                                         #go back one directory to get back to the go the the next random number in the file\n",
    "                                except:\n",
    "                                    pass                                                                                   #if the file already exist then pass on the function\n",
    "\n",
    "\n",
    "                    except:\n",
    "                        pass                                                                                               #if there are no files in the directory, pass\n",
    "\n",
    "\n",
    "            def run_action(year1,month1,day1,year2,month2,day2,threads):                                                      #run_action is a function that will be called to run all the MLB_GIDs part 1 of the project\n",
    "                Daysqueue = Queue()                                                                                        #create a queues for dates to be inserted into\n",
    "\n",
    "                \n",
    "                start = date(year1,month1,day1)                                                                            #using userinput, create an start date\n",
    "                today = date(year2,month2,day2)                                                                            #using userinput, create an end date\n",
    "                day = start                                                                                                #change of variable\n",
    "                while(day <= today):\n",
    "                    Daysqueue.put(day.isoformat())                                                                         #place the date into the queue, this is in isoformat , so it is a string. This is because the format is used to strip for the URLs above\n",
    "                    day += timedelta(1)                                                                                    #to the next day in the timeline\n",
    "                Daysqueue.put('Done')                                                                                      #place done at the end of the queue\n",
    "\n",
    "                num_threads = threads                                                                                      #create threads based on the userinput\n",
    "                thrds = []\n",
    "                for i in range(num_threads):                                                                               #do the multitreading based the queues and pass function as args\n",
    "                    p = Process(target = get_GIDs, args=[Daysqueue])\n",
    "                    thrds.append(p)                                                                                              \n",
    "                    p.start()                                                                                              #start the function, wait for threads to finish\n",
    "                for p in thrds:\n",
    "                    p.join\n",
    "                \n",
    "            run_action(int(inp1),int(inp2),int(inp3),int(inp4),int(inp5),int(inp6),int(inp7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your start year: 2018\n",
      "What is your start month: 1\n",
      "What is your start day: 1\n",
      "What is your end year: 2018\n",
      "What is your end month: 12\n",
      "What is your end day: 1\n",
      "How many threads: 1\n"
     ]
    }
   ],
   "source": [
    "retro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,zipfile,os,shutil,time,wget,re\n",
    "from pathlib import Path\n",
    "from multiprocessing import Process, Queue, Pool\n",
    "from datetime import date, timedelta\n",
    "def retro():\n",
    "        inp1 = int(input('What is your start year: '))                                  #UserInput of information\n",
    "        inp2 = int(input('What is your start month: '))\n",
    "        inp3 = int(input('What is your start day: '))\n",
    "        inp5 = int(input('What is your end year: '))                                  #UserInput of information\n",
    "        inp6 = int(input('What is your end month: '))\n",
    "        inp7 = int(input('What is your end day: '))\n",
    "        inp4 = int(input('How many threads: '))       \n",
    "\n",
    "\n",
    "        def get_GIDs(q):\n",
    "                '''\n",
    "                Function to get GameIDs \n",
    "                Input: Queue of dates \n",
    "                Output: Queue and dictionary of the Gids  \n",
    "                Note: Make sure the function of this directory is located in the \n",
    "                '''\n",
    "\n",
    "                day = q.get()\n",
    "                All_urls = []\n",
    "                Return_URl = []\n",
    "                while (day != 'Done'):\n",
    "                    All_urls.append('./MLB_Gameday_Data/year_' + str(day[0:4]) + '/month_'+ str(day[5:7]) + '/day_' + str(day[8:10]))      \n",
    "                    day = q.get()\n",
    "\n",
    "                list_Test = []\n",
    "                r = '(\\w+)/\\S\\S(\\w+_[0-9]{4}_[0-9]{2}_[0-9]{2}_\\w+_\\w+_[0-9])'\n",
    "                for i in range(0,len(All_urls)):\n",
    "                    with open(All_urls[i] + '/index.html', 'r') as f:\n",
    "                        try:\n",
    "                            lines = f.readlines()\n",
    "                            matches = re.finditer(r,str(lines))\n",
    "                            for m in matches:\n",
    "                                list_Test.append(m.group(1))\n",
    "                        except:\n",
    "                            pass\n",
    "                list_Test.sort()\n",
    "                cost = 0\n",
    "                for i in range(0,len(list_Test)-1):\n",
    "                    if list_Test[i] == list_Test[i+ 1]:\n",
    "                        cost += 1\n",
    "                print(cost)\n",
    "\n",
    "        def run_action(year1,month1,day1,year2,month2,day2,threads):   \n",
    "                #start_time = time.time()\n",
    "                Daysqueue = Queue()\n",
    "\n",
    "                os.chdir('/home/brian/Data3402/Project1')\n",
    "                start = date(year1,month1,day1)\n",
    "                today = date(year2,month2,day2)\n",
    "                day = start\n",
    "                while(day <= today):\n",
    "                    Daysqueue.put(day.isoformat())\n",
    "                    day += timedelta(1)\n",
    "                Daysqueue.put('Done')\n",
    "\n",
    "                num_threads = threads\n",
    "                thrds = []\n",
    "                for i in range(num_threads):\n",
    "                    p = Process(target = get_GIDs, args=[Daysqueue])\n",
    "                    thrds.append(p)\n",
    "                    p.start()\n",
    "\n",
    "                    #wait for threads to finish\n",
    "                for p in thrds:\n",
    "                    p.join\n",
    "                \n",
    "        run_action(int(inp1),int(inp2),int(inp3),int(inp5),int(inp6),int(inp7),int(inp4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your start year: 2018\n",
      "What is your start month: 1\n",
      "What is your start day: 1\n",
      "What is your end year: 2019\n",
      "What is your end month: 12\n",
      "What is your end day: 1\n",
      "How many threads: 1\n",
      "1011\n"
     ]
    }
   ],
   "source": [
    "retro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,zipfile,os,shutil,time,wget,re\n",
    "from pathlib import Path\n",
    "from multiprocessing import Process, Queue, Pool\n",
    "from datetime import date, timedelta\n",
    "def retro():\n",
    "        inp1 = int(input('What is your start year: '))                                  #UserInput of information\n",
    "        inp2 = int(input('What is your start month: '))\n",
    "        inp3 = int(input('What is your start day: '))\n",
    "        inp5 = int(input('What is your end year: '))                                  #UserInput of information\n",
    "        inp6 = int(input('What is your end month: '))\n",
    "        inp7 = int(input('What is your end day: '))\n",
    "        inp4 = int(input('How many threads: '))       \n",
    "\n",
    "\n",
    "        def get_GIDs(q):\n",
    "                '''\n",
    "                Function to get GameIDs \n",
    "                Input: Queue of dates \n",
    "                Output: Queue and dictionary of the Gids  \n",
    "                Note: Make sure the function of this directory is located in the \n",
    "                '''\n",
    "\n",
    "                day = q.get()\n",
    "                All_urls = []\n",
    "                Return_URl = []\n",
    "                while (day != 'Done'):\n",
    "                    All_urls.append('./MLB_Gameday_Data/year_' + str(day[0:4]) + '/month_'+ str(day[5:7]) + '/day_' + str(day[8:10]))      \n",
    "                    day = q.get()\n",
    "                ID_dic = {}\n",
    "                GID_queue = Queue()\n",
    "\n",
    "                r = '(\\w+)/\\S\\S(\\w+_[0-9]{4}_[0-9]{2}_[0-9]{2}_\\w+_\\w+_[0-9])'\n",
    "                for i in range(0,len(All_urls)):\n",
    "                    with open(All_urls[i] + '/index.html', 'r') as f:\n",
    "                        try:\n",
    "                            lines = f.readlines()\n",
    "                            matches = re.finditer(r,str(lines))\n",
    "                            for m in matches:\n",
    "                                GID_queue.put(m.group(2))\n",
    "                                ID_dic[m.group(2)] = m.group(1)\n",
    "                                Return_URl.append(All_urls[i])\n",
    "                        except:\n",
    "                            pass\n",
    "                GID_Search(ID_dic, GID_queue, All_urls)\n",
    "\n",
    "\n",
    "\n",
    "        def GID_Search(Dict, GID, url):\n",
    "                '''\n",
    "                Function to ccheck GID and game values\n",
    "                Input: Dictionary of game values and GIDs, a queue of GIDs \n",
    "                Output: Creation of a Directory with all the GIDs in them\n",
    "                Note: Make sure the function of this directory is located in the \n",
    "\n",
    "                let us make url a list too\n",
    "\n",
    "                '''\n",
    "                home_dir = os.getcwd()\n",
    "                MLB_GIDs =  Path('./MLB_GIDs')\n",
    "                if MLB_GIDs.exists() is False:\n",
    "                    os.makedirs('./MLB_GIDs')\n",
    "                Move_file = home_dir + '/MLB_GIDs'\n",
    "                GID.put('Done')\n",
    "                GameID = GID.get()\n",
    "                urlNumber = 0\n",
    "                while (GameID != 'Done' and urlNumber < len(url)):\n",
    "\n",
    "                    os.chdir(home_dir)\n",
    "                    os.chdir(url[urlNumber])\n",
    "                    #print(urlNumber)\n",
    "                    list_dir = os.listdir()\n",
    "\n",
    "                    urlNumber += 1\n",
    "                    try:\n",
    "                        for i in list_dir:\n",
    "                            Game_numbers = []\n",
    "                            if i != 'index.html':\n",
    "                                Game_numbers.append(i)\n",
    "\n",
    "                            for i in Game_numbers:\n",
    "                                for Game_ID, Code in Dict.items():\n",
    "                                        if Code == i:\n",
    "                                            File_name = Game_ID\n",
    "                                            print(i + Game_ID)\n",
    "                                            \n",
    "                                try:\n",
    "#                                     GID_path =  Path('./MLB_GIDs/' + str(File_name))\n",
    "#                                     if GID_path.exists() is False:\n",
    "#                                         os.makedirs(Move_file+ '/' + str(File_name))\n",
    "#                                     os.chdir('./' + i )\n",
    "#                                     #print(os.getcwd())\n",
    "#                                     xml_files = os.listdir()\n",
    "# #                                     print(xml_files)\n",
    "#                                     for i in xml_files:\n",
    "# #                                         print(str(i))\n",
    "#                                         shutil.copyfile(i, Move_file + '/' + str(File_name) + '/' + str(i))\n",
    "                                        \n",
    "                                    os.chdir('..')\n",
    "#                                    print(os.getcwd() + '/' + i)\n",
    "                                    #shutil.copytree(i, Move_file + '/' + File_name)\n",
    "                                except:\n",
    "                                    pass\n",
    "                                    #print('failed to move:' + i)\n",
    "\n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "\n",
    "        def run_action(year1,month1,day1,year2,month2,day2,threads):   \n",
    "                #start_time = time.time()\n",
    "                Daysqueue = Queue()\n",
    "\n",
    "                os.chdir('/home/brian/Data3402/Project1')\n",
    "                start = date(year1,month1,day1)\n",
    "                today = date(year2,month2,day2)\n",
    "                day = start\n",
    "                while(day <= today):\n",
    "                    Daysqueue.put(day.isoformat())\n",
    "                    day += timedelta(1)\n",
    "                Daysqueue.put('Done')\n",
    "\n",
    "                num_threads = threads\n",
    "                thrds = []\n",
    "                for i in range(num_threads):\n",
    "                    p = Process(target = get_GIDs, args=[Daysqueue])\n",
    "                    thrds.append(p)\n",
    "                    p.start()\n",
    "\n",
    "                    #wait for threads to finish\n",
    "                for p in thrds:\n",
    "                    p.join\n",
    "                \n",
    "        run_action(int(inp1),int(inp2),int(inp3),int(inp5),int(inp6),int(inp7),int(inp4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your start year: 2018\n",
      "What is your start month: 4\n",
      "What is your start day: 1\n",
      "What is your end year: 2018\n",
      "What is your end month: 4\n",
      "What is your end day: 9\n",
      "How many threads: 1\n",
      "6935911gid_2018_04_01_anamlb_oakmlb_1\n",
      "6935919gid_2018_04_01_pitmlb_detmlb_2\n",
      "6935922gid_2018_04_01_wasmlb_cinmlb_1\n",
      "6935922gid_2018_04_02_bosmlb_miamlb_1\n",
      "6935915gid_2018_04_01_houmlb_texmlb_1\n",
      "6935921gid_2018_04_01_slnmlb_nynmlb_1\n",
      "6935921gid_2018_04_02_balmlb_houmlb_1\n",
      "6935917gid_2018_04_01_nyamlb_tormlb_1\n",
      "6935918gid_2018_04_01_pitmlb_detmlb_1\n",
      "6935912gid_2018_04_01_bosmlb_tbamlb_1\n",
      "6935913gid_2018_04_01_chnmlb_miamlb_1\n",
      "6935920gid_2018_04_01_sfnmlb_lanmlb_1\n",
      "6935914gid_2018_04_01_clemlb_seamlb_1\n",
      "6935916gid_2018_04_01_minmlb_balmlb_1\n",
      "6935922gid_2018_04_01_wasmlb_cinmlb_1\n",
      "6935922gid_2018_04_02_bosmlb_miamlb_1\n",
      "6935932gid_2018_04_02_wasmlb_atlmlb_1\n",
      "6935932gid_2018_04_03_bosmlb_miamlb_1\n",
      "6935921gid_2018_04_01_slnmlb_nynmlb_1\n",
      "6935921gid_2018_04_02_balmlb_houmlb_1\n",
      "6935931gid_2018_04_02_texmlb_oakmlb_1\n",
      "6935931gid_2018_04_03_balmlb_houmlb_1\n",
      "6935924gid_2018_04_02_chnmlb_cinmlb_1\n",
      "6935926gid_2018_04_02_colmlb_sdnmlb_1\n",
      "6935929gid_2018_04_02_minmlb_pitmlb_1\n",
      "6935923gid_2018_04_02_chamlb_tormlb_1\n",
      "6935930gid_2018_04_02_slnmlb_milmlb_1\n",
      "6935925gid_2018_04_02_clemlb_anamlb_1\n",
      "6935927gid_2018_04_02_kcamlb_detmlb_1\n",
      "6935928gid_2018_04_02_lanmlb_arimlb_1\n",
      "6935936gid_2018_04_03_kcamlb_detmlb_1\n",
      "6935934gid_2018_04_03_clemlb_anamlb_1\n",
      "6935932gid_2018_04_02_wasmlb_atlmlb_1\n",
      "6935932gid_2018_04_03_bosmlb_miamlb_1\n",
      "6935935gid_2018_04_03_colmlb_sdnmlb_1\n",
      "6935941gid_2018_04_03_tbamlb_nyamlb_1\n",
      "6935941gid_2018_04_04_balmlb_houmlb_1\n",
      "6935943gid_2018_04_03_wasmlb_atlmlb_1\n",
      "6935943gid_2018_04_04_clemlb_anamlb_1\n",
      "6935939gid_2018_04_03_seamlb_sfnmlb_1\n",
      "6935937gid_2018_04_03_lanmlb_arimlb_1\n",
      "6935933gid_2018_04_03_chamlb_tormlb_1\n",
      "6935931gid_2018_04_02_texmlb_oakmlb_1\n",
      "6935931gid_2018_04_03_balmlb_houmlb_1\n",
      "6935938gid_2018_04_03_phimlb_nynmlb_1\n",
      "6935940gid_2018_04_03_slnmlb_milmlb_1\n",
      "6935942gid_2018_04_03_texmlb_oakmlb_1\n",
      "6935942gid_2018_04_04_chamlb_tormlb_1\n",
      "6935949gid_2018_04_04_slnmlb_milmlb_1\n",
      "6935952gid_2018_04_04_wasmlb_atlmlb_1\n",
      "6935952gid_2018_04_05_balmlb_nyamlb_1\n",
      "6935951gid_2018_04_04_texmlb_oakmlb_1\n",
      "6935951gid_2018_04_05_arimlb_slnmlb_1\n",
      "6935946gid_2018_04_04_minmlb_pitmlb_1\n",
      "6935945gid_2018_04_04_lanmlb_arimlb_1\n",
      "6935941gid_2018_04_03_tbamlb_nyamlb_1\n",
      "6935941gid_2018_04_04_balmlb_houmlb_1\n",
      "6935950gid_2018_04_04_tbamlb_nyamlb_1\n",
      "6935943gid_2018_04_03_wasmlb_atlmlb_1\n",
      "6935943gid_2018_04_04_clemlb_anamlb_1\n",
      "6935947gid_2018_04_04_phimlb_nynmlb_1\n",
      "6935944gid_2018_04_04_colmlb_sdnmlb_1\n",
      "6935948gid_2018_04_04_seamlb_sfnmlb_1\n",
      "6935942gid_2018_04_03_texmlb_oakmlb_1\n",
      "6935942gid_2018_04_04_chamlb_tormlb_1\n",
      "6935952gid_2018_04_04_wasmlb_atlmlb_1\n",
      "6935952gid_2018_04_05_balmlb_nyamlb_1\n",
      "6935956gid_2018_04_05_detmlb_chamlb_1\n",
      "6935951gid_2018_04_04_texmlb_oakmlb_1\n",
      "6935951gid_2018_04_05_arimlb_slnmlb_1\n",
      "6935959gid_2018_04_05_seamlb_minmlb_1\n",
      "6935958gid_2018_04_05_nynmlb_wasmlb_1\n",
      "6935960gid_2018_04_05_tbamlb_bosmlb_1\n",
      "6935961gid_2018_04_05_texmlb_oakmlb_1\n",
      "6935961gid_2018_04_06_atlmlb_colmlb_1\n",
      "6935955gid_2018_04_05_colmlb_sdnmlb_1\n",
      "6935953gid_2018_04_05_chnmlb_milmlb_1\n",
      "6935954gid_2018_04_05_cinmlb_pitmlb_1\n",
      "6935957gid_2018_04_05_miamlb_phimlb_1\n",
      "6935963gid_2018_04_06_chnmlb_milmlb_1\n",
      "6935968gid_2018_04_06_tormlb_texmlb_1\n",
      "6935967gid_2018_04_06_sdnmlb_houmlb_1\n",
      "6935964gid_2018_04_06_cinmlb_pitmlb_1\n",
      "6935965gid_2018_04_06_kcamlb_clemlb_1\n",
      "6935962gid_2018_04_06_balmlb_nyamlb_1\n",
      "6935961gid_2018_04_05_texmlb_oakmlb_1\n",
      "6935961gid_2018_04_06_atlmlb_colmlb_1\n",
      "6935966gid_2018_04_06_oakmlb_anamlb_1\n",
      "6935977gid_2018_04_07_kcamlb_clemlb_1\n",
      "6935978gid_2018_04_07_lanmlb_sfnmlb_1\n",
      "6935972gid_2018_04_07_atlmlb_colmlb_1\n",
      "6935983gid_2018_04_07_seamlb_minmlb_1\n",
      "6935983gid_2018_04_08_balmlb_nyamlb_1\n",
      "6935985gid_2018_04_07_tormlb_texmlb_1\n",
      "6935985gid_2018_04_08_cinmlb_pitmlb_1\n",
      "6935984gid_2018_04_07_tbamlb_bosmlb_1\n",
      "6935984gid_2018_04_08_chnmlb_milmlb_1\n",
      "6935974gid_2018_04_07_chnmlb_milmlb_1\n",
      "6935979gid_2018_04_07_miamlb_phimlb_1\n",
      "6935971gid_2018_04_07_arimlb_slnmlb_1\n",
      "6935980gid_2018_04_07_nynmlb_wasmlb_1\n",
      "6935976gid_2018_04_07_detmlb_chamlb_1\n",
      "6935975gid_2018_04_07_cinmlb_pitmlb_1\n",
      "6935982gid_2018_04_07_sdnmlb_houmlb_1\n",
      "6935982gid_2018_04_08_atlmlb_colmlb_1\n",
      "6935981gid_2018_04_07_oakmlb_anamlb_1\n",
      "6935981gid_2018_04_08_arimlb_slnmlb_1\n",
      "6935973gid_2018_04_07_balmlb_nyamlb_1\n",
      "6935983gid_2018_04_07_seamlb_minmlb_1\n",
      "6935983gid_2018_04_08_balmlb_nyamlb_1\n",
      "6935985gid_2018_04_07_tormlb_texmlb_1\n",
      "6935985gid_2018_04_08_cinmlb_pitmlb_1\n",
      "6935984gid_2018_04_07_tbamlb_bosmlb_1\n",
      "6935984gid_2018_04_08_chnmlb_milmlb_1\n",
      "6935994gid_2018_04_08_tormlb_texmlb_1\n",
      "6935994gid_2018_04_09_cinmlb_phimlb_1\n",
      "6935991gid_2018_04_08_oakmlb_anamlb_1\n",
      "6935991gid_2018_04_09_anamlb_texmlb_1\n",
      "6935990gid_2018_04_08_nynmlb_wasmlb_1\n",
      "6935987gid_2018_04_08_kcamlb_clemlb_1\n",
      "6935993gid_2018_04_08_tbamlb_bosmlb_1\n",
      "6935993gid_2018_04_09_atlmlb_wasmlb_1\n",
      "6935982gid_2018_04_07_sdnmlb_houmlb_1\n",
      "6935982gid_2018_04_08_atlmlb_colmlb_1\n",
      "6935981gid_2018_04_07_oakmlb_anamlb_1\n",
      "6935981gid_2018_04_08_arimlb_slnmlb_1\n",
      "6935988gid_2018_04_08_lanmlb_sfnmlb_1\n",
      "6935989gid_2018_04_08_miamlb_phimlb_1\n",
      "6935992gid_2018_04_08_sdnmlb_houmlb_1\n",
      "6935992gid_2018_04_09_arimlb_sfnmlb_1\n",
      "6935986gid_2018_04_08_detmlb_chamlb_1\n",
      "6935996gid_2018_04_09_houmlb_minmlb_1\n",
      "6936002gid_2018_04_09_tormlb_balmlb_1\n",
      "6935994gid_2018_04_08_tormlb_texmlb_1\n",
      "6935994gid_2018_04_09_cinmlb_phimlb_1\n",
      "6935991gid_2018_04_08_oakmlb_anamlb_1\n",
      "6935991gid_2018_04_09_anamlb_texmlb_1\n",
      "6935998gid_2018_04_09_nynmlb_miamlb_1\n",
      "6936000gid_2018_04_09_seamlb_kcamlb_1\n",
      "6935997gid_2018_04_09_milmlb_slnmlb_1\n",
      "6935993gid_2018_04_08_tbamlb_bosmlb_1\n",
      "6935993gid_2018_04_09_atlmlb_wasmlb_1\n",
      "6935995gid_2018_04_09_detmlb_clemlb_1\n",
      "6936001gid_2018_04_09_tbamlb_chamlb_1\n",
      "6935992gid_2018_04_08_sdnmlb_houmlb_1\n",
      "6935992gid_2018_04_09_arimlb_sfnmlb_1\n",
      "6935999gid_2018_04_09_sdnmlb_colmlb_1\n"
     ]
    }
   ],
   "source": [
    "retro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
